{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import new_models\n",
    "from config import load_data\n",
    "\n",
    "from ray import tune\n",
    "from ray.air.integrations.mlflow import MLflowLoggerCallback\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net, loss_function, optimizer, data_loader, num_epochs, mode, lr_scheduler, use_amp=False):\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp) # Mixed-precision support for compatible GPUs\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch < num_epochs - 1:\n",
    "            keys = [\"train\", \"val\"]\n",
    "        else:\n",
    "            keys = [\"train\", \"val\", \"test\"]\n",
    "        for key in keys:\n",
    "            dataset_size = 0\n",
    "            dataset_loss = 0.0\n",
    "            if key == \"train\":\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "            for X_batch, y_batch in tqdm(data_loader[key]):\n",
    "                X_batch, y_batch = X_batch.to(mode[\"device\"]), y_batch.to(mode[\"device\"])\n",
    "                with torch.set_grad_enabled(mode=(key==\"train\")): # Autograd activated only during training\n",
    "                    with torch.cuda.amp.autocast(enabled=False): # Mixed-precision support for compatible GPUs\n",
    "                        batch_output = net(X_batch.float())\n",
    "                        batch_loss = loss_function(batch_output, y_batch)\n",
    "                    if key == \"train\":\n",
    "                        scaler.scale(batch_loss).backward()\n",
    "                        scaler.step(optimizer) \t\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad()\n",
    "                dataset_size += y_batch.shape[0]\n",
    "                dataset_loss += y_batch.shape[0] * batch_loss.item()\n",
    "\n",
    "            dataset_loss /= dataset_size\n",
    "\n",
    "            # Report results to Ray Tune\n",
    "            if key == \"train\":\n",
    "                tune.report(train_loss=dataset_loss)\n",
    "            elif key == \"val\":\n",
    "                # Update learning rate\n",
    "                lr_scheduler.step(metrics=dataset_loss)\n",
    "                tune.report(val_loss=dataset_loss)\n",
    "            else:\n",
    "                tune.report(test_loss=dataset_loss)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import load_data\n",
    "\n",
    "def train_model(config, data_dir):\n",
    "\n",
    "    use_GPU = torch.cuda.is_available()\n",
    "    if use_GPU:\n",
    "        mode = {\"name\": \"cuda\", \"device\": torch.device(\"cuda\")}\n",
    "    else:\n",
    "        mode = {\"name\": \"cpu\", \"device\": torch.device(\"cpu\")}\n",
    "\n",
    "    # Define hyperparameters\n",
    "    train_size = 0.7\n",
    "    val_size = 0.2\n",
    "    test_size = 0.1\n",
    "\n",
    "    sequence_length = config['sequence_length']\n",
    "    batch_size = config['batch_size']\n",
    "    num_epochs = config['num_epochs']\n",
    "    lr = config['lr']\n",
    "    weight_decay = config['weigth_decay']\n",
    "    vars = config['variables']\n",
    "\n",
    "    ld = load_data(data_dir = data_dir, target_variable = config['target_variable'])\n",
    "    \n",
    "    X, y = ld.create_lagged_matrix(window_size=sequence_length, vars_to_lag=vars)\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = ld.split_data(X, y, train_size=train_size, val_size=val_size, test_size=test_size)\n",
    "\n",
    "    train_dataloader = ld.create_dataloader(X_train, y_train, sequence_length, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = ld.create_dataloader(X_val, y_val, sequence_length, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = ld.create_dataloader(X_test, y_test, sequence_length, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Model inputs\n",
    "    if vars:\n",
    "        input_size = len(vars) + 1\n",
    "    else:\n",
    "        input_size = 1\n",
    "    hidden_size = config['hidden_size']\n",
    "    num_layers = config['num_layers']\n",
    "    output_size = 1\n",
    "\n",
    "    if config['arch'] == \"FCN\":\n",
    "        net = new_models.FCN(input_size,\n",
    "                    hidden_size,\n",
    "                    num_layers,\n",
    "                    output_size,\n",
    "                    )\n",
    "    elif config['arch'] ==  \"FCNTemporalAttention\":\n",
    "        net = new_models.FCNTemporalAttention(input_size,\n",
    "                    hidden_size,\n",
    "                    num_layers,\n",
    "                    output_size,\n",
    "                    )\n",
    "    elif config['arch'] == \"LSTM\":\n",
    "        net = new_models.LSTM(input_size,\n",
    "                    hidden_size,\n",
    "                    num_layers,\n",
    "                    output_size,\n",
    "                    )\n",
    "    elif config['arch'] == \"LSTMTemporalAttention\":\n",
    "        net = new_models.LSTMTemporalAttention(input_size,\n",
    "                    hidden_size,\n",
    "                    num_layers,\n",
    "                    output_size,\n",
    "                    )\n",
    "\n",
    "    data_loader = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"val\": val_dataloader,\n",
    "    \"test\": test_dataloader,\n",
    "    }\n",
    "    \n",
    "    net.to(mode[\"device\"])\n",
    "\n",
    "    loss_function = nn.MSELoss().to(mode[\"device\"])\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Define your learning rate scheduler\n",
    "    lr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "                                           \n",
    "    best_net = fit(net, loss_function, optimizer, data_loader, num_epochs, mode, lr_scheduler, use_amp=True)\n",
    "    out_name = \"\"\n",
    "    for k, v in config.items():\n",
    "        if not k in ['weights_dir', 'cwd', 'variables']:\n",
    "            out_name += '{}-{}_'.format(k, v)\n",
    "    torch.save(best_net.state_dict(), os.path.join(config['cwd'], config['weights_dir'], out_name[:-1] + '.pth'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "cwd = os.getcwd()\n",
    "exp_base_name = \"Test_of_interface\"\n",
    "\n",
    "created = 0\n",
    "for i in range(100):\n",
    "    try:\n",
    "        exp_name = exp_base_name+\"_{}\".format(i)\n",
    "        experiment_id = client.create_experiment(exp_name)\n",
    "        created=1\n",
    "        break\n",
    "    except (TypeError, mlflow.exceptions.MlflowException):\n",
    "        continue\n",
    "\n",
    "if not created:\n",
    "    print(\"ERROR: Try new experiment name.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "weights_root = \"./model_weights/\"\n",
    "weights_dir = weights_root+exp_name+'/'\n",
    "os.mkdir(weights_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/\"\n",
    "target_variable = 'Q_Kalltveit'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Discharge = [\"Q_Kalltveit_uten_tapping\", \"Q_Lyngsaana\"]\n",
    "HBV = [\"Q_HBV_mean\", \"Q_HBV\", \"Evap_HBV\", \"SNOW_MELT_HBV\", \"PRECIP_HBV\", \"GR_WAT_HBV\", \"TEMP_HBV\", \"SOIL_WAT_HBV\"]\n",
    "Loggers = ['Vannstand Lyngsåna','Vanntemp. Hiafossen', 'Vannstand Hiafossen', 'Vannstand Kalltveit', 'Vanntemp. Kalltveit kum', 'Vanntemp. Hiavatn', 'Vannstand Hiavatn', 'Vanntemp. Musdalsvatn', 'Vannstand Musdalsvatn', 'Vanntemp. Musdalsvatn nedstrøms', 'Vannstand Musdalsvatn nedstrøms', 'Vanntemp. Viglesdalsvatn', 'Vannstand Viglesdalsvatn', 'Vanntemp. Lyngsåna', 'Vanntemp. Kalltveit elv']\n",
    "Loggers_1 = ['Vannstand Lyngsåna', 'Vanntemp. Lyngsåna']\n",
    "Loggers_2 = ['Vannstand Hiafossen']\n",
    "Loggers_3 = ['Vannstand Kalltveit', 'Vanntemp. Kalltveit kum']\n",
    "Loggers_4 = ['Vanntemp. Hiavatn', 'Vannstand Hiavatn']\n",
    "Loggers_5 = ['Vanntemp. Musdalsvatn', 'Vannstand Musdalsvatn']\n",
    "Loggers_6 = ['Vanntemp. Musdalsvatn nedstrøms', 'Vannstand Musdalsvatn nedstrøms']\n",
    "Loggers_7 = ['Vanntemp. Viglesdalsvatn', 'Vannstand Viglesdalsvatn']\n",
    "Loggers_8 = ['Vanntemp. Kalltveit elv']\n",
    "Meto = ['Nedbør Nilsebu', 'Nedbør Fister', 'Lufttemp Fister', 'Lufttemp. Nilsebu', 'RelHum Nilsebu', 'Vindretning Nilsebu']\n",
    "Meto_1 = ['Nedbør Nilsebu', 'Lufttemp. Nilsebu', 'RelHum Nilsebu', 'Vindretning Nilsebu']\n",
    "Meto_2 = ['Nedbør Fister', 'Lufttemp Fister']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-25 22:42:11</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:03.76        </td></tr>\n",
       "<tr><td>Memory:      </td><td>12.8/31.9 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 12.0/12 CPUs, 1.0/1 GPUs, 0.0/12.04 GiB heap, 0.0/6.02 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th>arch                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_epochs</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  sequence_length</th><th>variables           </th><th style=\"text-align: right;\">  weigth_decay</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_e4340_00000</td><td>RUNNING </td><td>127.0.0.1:12984</td><td>LSTMTemporalAtt_9df0</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.0744653  </td><td style=\"text-align: right;\">         150</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">               25</td><td>[&#x27;Q_Kalltveit_u_4608</td><td style=\"text-align: right;\">        0     </td></tr>\n",
       "<tr><td>train_model_e4340_00001</td><td>PENDING </td><td>               </td><td>LSTMTemporalAtt_9df0</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.000202282</td><td style=\"text-align: right;\">         150</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">               25</td><td>[&#x27;Q_Kalltveit_u_42c8</td><td style=\"text-align: right;\">        0     </td></tr>\n",
       "<tr><td>train_model_e4340_00002</td><td>PENDING </td><td>               </td><td>LSTMTemporalAtt_9df0</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.00135145 </td><td style=\"text-align: right;\">         150</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">               25</td><td>[&#x27;Q_Kalltveit_u_ce48</td><td style=\"text-align: right;\">        0.0001</td></tr>\n",
       "<tr><td>train_model_e4340_00003</td><td>PENDING </td><td>               </td><td>LSTMTemporalAtt_9df0</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.00324179 </td><td style=\"text-align: right;\">         150</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">               25</td><td>[&#x27;Q_Kalltveit_u_4c88</td><td style=\"text-align: right;\">        0.0001</td></tr>\n",
       "<tr><td>train_model_e4340_00004</td><td>PENDING </td><td>               </td><td>LSTMTemporalAtt_9df0</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.0774627  </td><td style=\"text-align: right;\">         150</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">               25</td><td>[&#x27;Q_Kalltveit_u_a588</td><td style=\"text-align: right;\">        0.0001</td></tr>\n",
       "<tr><td>train_model_e4340_00005</td><td>PENDING </td><td>               </td><td>LSTMTemporalAtt_9df0</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.000412547</td><td style=\"text-align: right;\">         150</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">               25</td><td>[&#x27;Q_Kalltveit_u_0f48</td><td style=\"text-align: right;\">        0     </td></tr>\n",
       "<tr><td>train_model_e4340_00006</td><td>PENDING </td><td>               </td><td>LSTMTemporalAtt_9df0</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.000458117</td><td style=\"text-align: right;\">         150</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">               25</td><td>[&#x27;Q_Kalltveit_u_4cc8</td><td style=\"text-align: right;\">        0.001 </td></tr>\n",
       "<tr><td>train_model_e4340_00007</td><td>PENDING </td><td>               </td><td>LSTMTemporalAtt_9df0</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.00098221 </td><td style=\"text-align: right;\">         150</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">               25</td><td>[&#x27;Q_Kalltveit_u_5c88</td><td style=\"text-align: right;\">        0.0001</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=12984)\u001b[0m c:\\Code\\hydro-ml\\my_env\\lib\\site-packages\\pandas\\core\\indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[2m\u001b[36m(func pid=12984)\u001b[0m   self.obj[key] = value\n",
      "2023-03-25 22:42:25,446\tERROR trial_runner.py:1088 -- Trial train_model_e4340_00000: Error processing event.\n",
      "ray.exceptions.RayTaskError(FileNotFoundError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=12984, ip=127.0.0.1, repr=func)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Code\\hydro-ml\\my_env\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"c:\\Code\\hydro-ml\\my_env\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"c:\\Code\\hydro-ml\\my_env\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 367, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"c:\\Code\\hydro-ml\\my_env\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 338, in entrypoint\n",
      "    self._status_reporter.get_checkpoint(),\n",
      "  File \"c:\\Code\\hydro-ml\\my_env\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"c:\\Code\\hydro-ml\\my_env\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 652, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"C:\\Users\\magnu\\AppData\\Local\\Temp\\ipykernel_22872\\4018297693.py\", line 25, in train_model\n",
      "  File \"c:\\Code\\hydro-ml\\config\\load_data.py\", line 88, in create_lagged_matrix\n",
      "    lagged_df.to_csv(path, index=True)\n",
      "  File \"c:\\Code\\hydro-ml\\my_env\\lib\\site-packages\\pandas\\core\\generic.py\", line 3482, in to_csv\n",
      "    storage_options=storage_options,\n",
      "  File \"c:\\Code\\hydro-ml\\my_env\\lib\\site-packages\\pandas\\io\\formats\\format.py\", line 1105, in to_csv\n",
      "    csv_formatter.save()\n",
      "  File \"c:\\Code\\hydro-ml\\my_env\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\", line 243, in save\n",
      "    storage_options=self.storage_options,\n",
      "  File \"c:\\Code\\hydro-ml\\my_env\\lib\\site-packages\\pandas\\io\\common.py\", line 707, in get_handle\n",
      "    newline=\"\",\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'c:\\\\Code\\\\hydro-ml./data/clean_data\\\\multivariate\\\\Q_Kalltveit\\\\25_lag_Q_Kalltveit_uten_tapping_Q_Lyngsaana_Q_HBV_mean_Q_HBV_Evap_HBV_SNOW_MELT_HBV_PRECIP_HBV_GR_WAT_HBV_TEMP_HBV_SOIL_WAT_HBV_Vannstand Lyngsåna_Vanntemp. Lyngsåna_Nedbør Nilsebu_Lufttemp. Nilsebu_RelHum Nilsebu_Vindretning Nilsebu.csv'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>date               </th><th>experiment_id                   </th><th>hostname       </th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_e4340_00000</td><td>2023-03-25_22-42-11</td><td>789dd0320342427498ca9443c61ef527</td><td>DESKTOP-D4IVECG</td><td>127.0.0.1</td><td style=\"text-align: right;\">12984</td><td style=\"text-align: right;\"> 1679780531</td><td>e4340_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 22:42:29,337\tWARNING tune.py:691 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "  0%|          | 0/23 [00:00<?, ?it/s]\n",
      "  4%|▍         | 1/23 [00:00<00:06,  3.16it/s]\n",
      " 30%|███       | 7/23 [00:00<00:00, 20.42it/s]\n",
      " 61%|██████    | 14/23 [00:00<00:00, 34.43it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 34.79it/s]\n",
      "2023-03-25 22:42:33,261\tERROR tune.py:758 -- Trials did not complete: [train_model_e4340_00000, train_model_e4340_00001, train_model_e4340_00002, train_model_e4340_00003, train_model_e4340_00004, train_model_e4340_00005, train_model_e4340_00006, train_model_e4340_00007]\n",
      "2023-03-25 22:42:33,262\tINFO tune.py:763 -- Total run time: 25.31 seconds (23.37 seconds for the tuning loop).\n",
      "2023-03-25 22:42:33,262\tWARNING tune.py:769 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "config = {\n",
    "    \"mlflow_experiment_id\": experiment_id,\n",
    "    \"weights_dir\": weights_dir,\n",
    "    \"cwd\": cwd,\n",
    "    \"target_variable\": target_variable,\n",
    "    \"arch\": tune.grid_search([\"LSTMTemporalAttention\"]), # \"FCN\", \"FCNTemporalAttention\", \n",
    "    \"sequence_length\": tune.grid_search([25]),\n",
    "    'num_epochs': tune.grid_search([150]),\n",
    "    'num_layers': tune.choice([2, 3, 4]),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"weigth_decay\": tune.choice([0, 0.001, 0.0001]),\n",
    "    \"batch_size\": tune.choice([256, 256*2]),\n",
    "    \"hidden_size\": tune.grid_search([64]),\n",
    "    \"variables\": tune.grid_search([\n",
    "        Discharge + HBV + Loggers_1 + Meto_1,\n",
    "        Discharge + HBV + Loggers_1 + Meto_2,\n",
    "        Discharge + HBV + Loggers_4 + Meto_1,\n",
    "        Discharge + HBV + Loggers_4 + Meto_2,\n",
    "    ])\n",
    "}\n",
    "\n",
    "analysis = tune.run(\n",
    "    partial(train_model, data_dir=data_dir),\n",
    "    config=config,\n",
    "    resources_per_trial={\"cpu\": 12, \"gpu\": 1},\n",
    "    num_samples=2,\n",
    "    callbacks=[MLflowLoggerCallback(experiment_name=exp_name)],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab06ce908a8abf9762b166587a79a7b3fe0760e63d13e53395d21ef1a2a21042"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
