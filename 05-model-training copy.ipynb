{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ray import tune\n",
    "from ray.air import session\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from src.models import *\n",
    "from src.data import Data\n",
    "from src.train import fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'Flow_Kalltveit'\n",
    "file_name = \"cleaned_data_1.csv\"\n",
    "data_dir = \"../data\"\n",
    "datetime_variable = \"Datetime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, checkpoint_dir=None):\n",
    "    use_GPU = torch.cuda.is_available()\n",
    "    if use_GPU:\n",
    "        mode = {\"name\": \"cuda\", \"device\": torch.device(\"cuda\")}\n",
    "    else:\n",
    "        mode = {\"name\": \"cpu\", \"device\": torch.device(\"cpu\")}\n",
    "\n",
    "    # Define hyperparameters\n",
    "    train_size = 0.7\n",
    "    val_size = 0.2\n",
    "    test_size = 0.1\n",
    "\n",
    "    sequence_length = config['sequence_length']\n",
    "    batch_size = config['batch_size']\n",
    "    num_epochs = config['num_epochs']\n",
    "    lr = config['learning_rate']\n",
    "    weight_decay = config['weigth_decay']\n",
    "\n",
    "    # Set data file\n",
    "    data_file = config['data_file']\n",
    "    datetime_variable = config['datetime']\n",
    "\n",
    "    data = Data(data_file, datetime_variable)\n",
    "\n",
    "    # Select variables to use\n",
    "    vars = config['variables']\n",
    "    target_variable = config['target_variable']\n",
    "    X, y = data.data_transformation(sequence_length=sequence_length, target_variable=target_variable, columns_to_transformation=vars)\n",
    "\n",
    "    # Split the data\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = data.split_data(X, y, train_size=train_size, val_size=val_size, test_size=test_size)\n",
    "    train_dataloader = data.create_dataloader(X_train, y_train, sequence_length, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = data.create_dataloader(X_val, y_val, sequence_length, batch_size=batch_size, shuffle=False)\n",
    "    test_dataloader = data.create_dataloader(X_test, y_test, sequence_length, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Model inputs\n",
    "    if vars:\n",
    "        input_size = len(vars) + 1\n",
    "    else:\n",
    "        input_size = 1\n",
    "    hidden_size = config['hidden_size']\n",
    "    num_layers = config['num_layers']\n",
    "    output_size = 1\n",
    "\n",
    "    if config['arch'] == \"FCN\":\n",
    "        net = FCN(input_size,\n",
    "                    hidden_size,\n",
    "                    num_layers,\n",
    "                    output_size,\n",
    "                    )\n",
    "    elif config['arch'] ==  \"FCNTemporalAttention\":\n",
    "        net = FCNTemporalAttention(input_size,\n",
    "                    hidden_size,\n",
    "                    num_layers,\n",
    "                    output_size,\n",
    "                    )\n",
    "    elif config['arch'] == \"LSTM\":\n",
    "        net = LSTM(input_size,\n",
    "                    hidden_size,\n",
    "                    num_layers,\n",
    "                    output_size,\n",
    "                    )\n",
    "    elif config['arch'] == \"LSTMTemporalAttention\":\n",
    "        net = LSTMTemporalAttention(input_size,\n",
    "                    hidden_size,\n",
    "                    num_layers,\n",
    "                    output_size,\n",
    "                    )\n",
    "    elif config['arch'] == \"LSTMSpatialAttention\":\n",
    "        net = LSTMSpatialAttention(input_size,\n",
    "                    hidden_size,\n",
    "                    num_layers,\n",
    "                    output_size,\n",
    "                    )\n",
    "    elif config['arch'] == \"LSTMSpatialTemporalAttention\":\n",
    "        net = LSTMSpatialTemporalAttention(input_size,\n",
    "                    hidden_size,\n",
    "                    num_layers,\n",
    "                    output_size,\n",
    "                    )\n",
    "\n",
    "    data_loader = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"val\": val_dataloader,\n",
    "    \"test\": test_dataloader,\n",
    "    }\n",
    "    \n",
    "    net.to(mode[\"device\"])\n",
    "\n",
    "    loss_function = nn.MSELoss().to(mode[\"device\"])\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    fit(net, loss_function, optimizer, data_loader, num_epochs, mode, checkpoint_dir, use_amp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-04-02 20:17:28</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:08.57        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.3/31.9 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 12.0/12 CPUs, 1.0/1 GPUs, 0.0/13.16 GiB heap, 0.0/6.58 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  w_decay</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_epochs</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  test_loss</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_9b4cb_00000</td><td>RUNNING </td><td>127.0.0.1:6140</td><td style=\"text-align: right;\">   0.001 </td><td style=\"text-align: right;\">0.00749158 </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     45.4932</td><td style=\"text-align: right;\">   15.6453</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>train_model_9b4cb_00001</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">   0     </td><td style=\"text-align: right;\">0.000141852</td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>train_model_9b4cb_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">   0.0001</td><td style=\"text-align: right;\">0.000529995</td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>train_model_9b4cb_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">   0.001 </td><td style=\"text-align: right;\">0.00944205 </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>train_model_9b4cb_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">   0     </td><td style=\"text-align: right;\">0.0880001  </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>train_model_9b4cb_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">   0.001 </td><td style=\"text-align: right;\">0.000547444</td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>train_model_9b4cb_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">   0     </td><td style=\"text-align: right;\">0.0101135  </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>train_model_9b4cb_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">   0.001 </td><td style=\"text-align: right;\">0.00358019 </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>train_model_9b4cb_00008</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">   0     </td><td style=\"text-align: right;\">0.0205189  </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>train_model_9b4cb_00009</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">   0.0001</td><td style=\"text-align: right;\">0.0652741  </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>train_model_9b4cb_00010</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">   0.001 </td><td style=\"text-align: right;\">0.00703207 </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "<tr><td>train_model_9b4cb_00011</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">   0.001 </td><td style=\"text-align: right;\">0.086774   </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">                    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-02 20:17:18,485\tINFO worker.py:1553 -- Started a local Ray instance.\n",
      "c:\\Code\\Master\\hydro-ml\\.venv\\lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py:612: DeprecationWarning: `checkpoint_dir` in `func(config, checkpoint_dir)` is being deprecated. To save and load checkpoint in trainable functions, please use the `ray.air.session` API:\n",
      "\n",
      "from ray.air import session\n",
      "\n",
      "def train(config):\n",
      "    # ...\n",
      "    session.report({\"metric\": metric}, checkpoint=checkpoint)\n",
      "\n",
      "For more information please see https://docs.ray.io/en/master/tune/api_docs/trainable.html\n",
      "\n",
      "  warnings.warn(\n",
      "  0%|          | 0/178 [00:00<?, ?it/s]\n",
      "  1%|          | 1/178 [00:00<00:53,  3.28it/s]\n",
      " 10%|█         | 18/178 [00:00<00:02, 55.27it/s]\n",
      " 18%|█▊        | 32/178 [00:00<00:01, 81.27it/s]\n",
      " 28%|██▊       | 50/178 [00:00<00:01, 110.61it/s]\n",
      " 38%|███▊      | 67/178 [00:00<00:00, 128.20it/s]\n",
      " 48%|████▊     | 86/178 [00:00<00:00, 145.97it/s]\n",
      " 60%|█████▉    | 106/178 [00:00<00:00, 160.42it/s]\n",
      "2023-04-02 20:17:27,994\tWARNING tune.py:146 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      " 71%|███████   | 126/178 [00:01<00:00, 169.19it/s]\n",
      " 83%|████████▎ | 147/178 [00:01<00:00, 178.88it/s]\n",
      " 94%|█████████▍| 168/178 [00:01<00:00, 186.68it/s]\n",
      "100%|██████████| 178/178 [00:01<00:00, 128.93it/s]\n",
      "  0%|          | 0/45 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-02 20:17:28,595\tERROR tune.py:794 -- Trials did not complete: [train_model_9b4cb_00000, train_model_9b4cb_00001, train_model_9b4cb_00002, train_model_9b4cb_00003, train_model_9b4cb_00004, train_model_9b4cb_00005, train_model_9b4cb_00006, train_model_9b4cb_00007, train_model_9b4cb_00008, train_model_9b4cb_00009, train_model_9b4cb_00010, train_model_9b4cb_00011]\n",
      "2023-04-02 20:17:28,595\tINFO tune.py:798 -- Total run time: 8.62 seconds (8.56 seconds for the tuning loop).\n",
      "2023-04-02 20:17:28,595\tWARNING tune.py:804 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 254.11it/s]\n",
      "  0%|          | 0/178 [00:00<?, ?it/s]\n",
      "  9%|▉         | 16/178 [00:00<00:01, 157.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "\n",
    "config = {\n",
    "    \"data_file\": file_name,\n",
    "    \"datetime\":  datetime_variable,\n",
    "    \"target_variable\": target_variable,\n",
    "    \"arch\": tune.grid_search([\"LSTM\", \"LSTMTemporalAttention\", \"LSTMSpatialAttention\", \"LSTMSpatialTemporalAttention\"]), # \"FCN\", \"FCNTemporalAttention\", \"LSTMTemporalAttention\", \"LSTM\", \"LSTMSpatialAttention\", \"LSTMSpatialTemporalAttention\"\n",
    "    \"sequence_length\": tune.choice([25]),\n",
    "    'num_epochs': tune.choice([30]),\n",
    "    'num_layers': tune.choice([2, 3, 4]),\n",
    "    \"learning_rate\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"weigth_decay\": tune.choice([0, 0.001, 0.0001]),\n",
    "    \"batch_size\": tune.choice([256, 512]),\n",
    "    \"hidden_size\": tune.choice([32, 64]),\n",
    "    \"variables\": tune.grid_search([\n",
    "        None,\n",
    "        [\"Wind_Speed_Nilsebu\", \"Air_Temperature_Nilsebu\", \"Wind_Direction_Nilsebu\", \"Relative_Humidity_Nilsebu\", \"Air_Temperature_Fister\", \"Precipitation_Fister\", \"Flow_Lyngsvatn_Overflow\", \"Flow_Tapping\", \"Water_Level_Kalltveit\", \"Water_Temperature_Kalltveit_Kum\", \"Precipitation_Nilsebu\", \"Flow_HBV\", \"Precipitation_HBV\", \"Temperature_HBV\", \"Flow_Without_Tapping_Kalltveit\", \"Flow_Lyngsaana\", \"Water_Temperature_Lyngsaana\"],\n",
    "    ])\n",
    "}\n",
    "scheduler = ASHAScheduler( # TODO: Find a scheduler that works better\n",
    "    metric=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    max_t=100,\n",
    "    grace_period=5,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "reporter = tune.JupyterNotebookReporter(\n",
    "        parameter_columns={\n",
    "            \"weigth_decay\": \"w_decay\",\n",
    "            \"learning_rate\": \"lr\",\n",
    "            \"num_epochs\": \"num_epochs\"\n",
    "        },\n",
    "        metric_columns=[\n",
    "            \"train_loss\", \"val_loss\", \"test_loss\", \"training_iteration\"\n",
    "        ])\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_model, # TODO: partial(train_cifar, data_dir=data_dir),\n",
    "    resources_per_trial={\"cpu\": 12, \"gpu\": 1},\n",
    "    config=config,\n",
    "    num_samples=1,\n",
    "    #scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    name=\"inflow_forecasting\",\n",
    "    \n",
    ")#time_total_s require_attrs=False,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest config: \u001b[39m\u001b[39m\"\u001b[39m, analysis\u001b[39m.\u001b[39mget_best_config(\n\u001b[0;32m      2\u001b[0m    metric\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[39m# Get a dataframe for analyzing trial results.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df \u001b[39m=\u001b[39m analysis\u001b[39m.\u001b[39mresults_df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'analysis' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Best config: \", analysis.get_best_config(\n",
    "   metric=\"val_loss\", mode=\"min\"))\n",
    "# Get a dataframe for analyzing trial results.\n",
    "df = analysis.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>should_checkpoint</th>\n",
       "      <th>done</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>episodes_total</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>...</th>\n",
       "      <th>config/target_variable</th>\n",
       "      <th>config/arch</th>\n",
       "      <th>config/sequence_length</th>\n",
       "      <th>config/num_epochs</th>\n",
       "      <th>config/num_layers</th>\n",
       "      <th>config/learning_rate</th>\n",
       "      <th>config/weigth_decay</th>\n",
       "      <th>config/batch_size</th>\n",
       "      <th>config/hidden_size</th>\n",
       "      <th>config/variables</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4590b_00000</th>\n",
       "      <td>20.018083</td>\n",
       "      <td>9.753485</td>\n",
       "      <td>13.834575</td>\n",
       "      <td>1.010038</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>885b61288c2d421b97179ed96ab87ec0</td>\n",
       "      <td>...</td>\n",
       "      <td>Flow_Kalltveit</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.077368</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4590b_00001</th>\n",
       "      <td>8.418127</td>\n",
       "      <td>1.886700</td>\n",
       "      <td>5.245848</td>\n",
       "      <td>1.107213</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>ab9b712dfee54d7b90d29f5bbddd1f24</td>\n",
       "      <td>...</td>\n",
       "      <td>Flow_Kalltveit</td>\n",
       "      <td>LSTMTemporalAttention</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>256</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4590b_00002</th>\n",
       "      <td>1.208316</td>\n",
       "      <td>0.276047</td>\n",
       "      <td>0.378798</td>\n",
       "      <td>1.316164</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>8fd698226f1e470d87ba22256b6d9ffa</td>\n",
       "      <td>...</td>\n",
       "      <td>Flow_Kalltveit</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>[Air_Temperature_Fister, Precipitation_Fister]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4590b_00003</th>\n",
       "      <td>1.032035</td>\n",
       "      <td>0.958731</td>\n",
       "      <td>0.712596</td>\n",
       "      <td>1.257438</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>d999283521424638a4414d1069294d0c</td>\n",
       "      <td>...</td>\n",
       "      <td>Flow_Kalltveit</td>\n",
       "      <td>LSTMTemporalAttention</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.007805</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>32</td>\n",
       "      <td>[Air_Temperature_Fister, Precipitation_Fister]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             train_loss  val_loss  test_loss  time_this_iter_s  \\\n",
       "trial_id                                                         \n",
       "4590b_00000   20.018083  9.753485  13.834575          1.010038   \n",
       "4590b_00001    8.418127  1.886700   5.245848          1.107213   \n",
       "4590b_00002    1.208316  0.276047   0.378798          1.316164   \n",
       "4590b_00003    1.032035  0.958731   0.712596          1.257438   \n",
       "\n",
       "             should_checkpoint  done timesteps_total episodes_total  \\\n",
       "trial_id                                                              \n",
       "4590b_00000               True  True            None           None   \n",
       "4590b_00001               True  True            None           None   \n",
       "4590b_00002               True  True            None           None   \n",
       "4590b_00003               True  True            None           None   \n",
       "\n",
       "             training_iteration                     experiment_id  ...  \\\n",
       "trial_id                                                           ...   \n",
       "4590b_00000                  30  885b61288c2d421b97179ed96ab87ec0  ...   \n",
       "4590b_00001                  30  ab9b712dfee54d7b90d29f5bbddd1f24  ...   \n",
       "4590b_00002                  30  8fd698226f1e470d87ba22256b6d9ffa  ...   \n",
       "4590b_00003                  30  d999283521424638a4414d1069294d0c  ...   \n",
       "\n",
       "            config/target_variable            config/arch  \\\n",
       "trial_id                                                    \n",
       "4590b_00000         Flow_Kalltveit                   LSTM   \n",
       "4590b_00001         Flow_Kalltveit  LSTMTemporalAttention   \n",
       "4590b_00002         Flow_Kalltveit                   LSTM   \n",
       "4590b_00003         Flow_Kalltveit  LSTMTemporalAttention   \n",
       "\n",
       "             config/sequence_length  config/num_epochs config/num_layers  \\\n",
       "trial_id                                                                   \n",
       "4590b_00000                      25                 30                 3   \n",
       "4590b_00001                      25                 30                 2   \n",
       "4590b_00002                      25                 30                 4   \n",
       "4590b_00003                      25                 30                 4   \n",
       "\n",
       "            config/learning_rate  config/weigth_decay  config/batch_size  \\\n",
       "trial_id                                                                   \n",
       "4590b_00000             0.077368               0.0001                256   \n",
       "4590b_00001             0.000381               0.0000                256   \n",
       "4590b_00002             0.000599               0.0001                256   \n",
       "4590b_00003             0.007805               0.0010                256   \n",
       "\n",
       "             config/hidden_size  \\\n",
       "trial_id                          \n",
       "4590b_00000                  32   \n",
       "4590b_00001                  32   \n",
       "4590b_00002                  64   \n",
       "4590b_00003                  32   \n",
       "\n",
       "                                           config/variables  \n",
       "trial_id                                                     \n",
       "4590b_00000                                            None  \n",
       "4590b_00001                                            None  \n",
       "4590b_00002  [Air_Temperature_Fister, Precipitation_Fister]  \n",
       "4590b_00003  [Air_Temperature_Fister, Precipitation_Fister]  \n",
       "\n",
       "[4 rows x 33 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscheduler = PopulationBasedTraining(\\n    time_attr=\"training_iteration\",\\n    metric=\"val_loss\",\\n    mode=\"min\",\\n    perturbation_interval=2,\\n    hyperparam_mutations={\\n        \"weigth_decay\": tune.uniform(0.0, 0.3),\\n        \"learning_rate\": tune.uniform(1e-5, 5e-5),\\n    },\\n)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    \"model\": {\n",
    "        \"hidden_size\": tune.choice([32, 64, 128]),\n",
    "        \"num_layers\": tune.choice([1, 2, 3]),\n",
    "    },\n",
    "\n",
    "    model = YourModel(**config[\"model\"]).to(device)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "scheduler = PopulationBasedTraining(\n",
    "    time_attr=\"training_iteration\",\n",
    "    metric=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    perturbation_interval=2,\n",
    "    hyperparam_mutations={\n",
    "        \"weigth_decay\": tune.uniform(0.0, 0.3),\n",
    "        \"learning_rate\": tune.uniform(1e-5, 5e-5),\n",
    "    },\n",
    ")\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydro-ml",
   "language": "python",
   "name": "hydro-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
